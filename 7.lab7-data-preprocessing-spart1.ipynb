{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Lab\n",
    "\n",
    "## Data understanding and preprocessing - Walkthrough of Traveler dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### * Goal: Predict the country that users will make their first booking in, based on some basic user profile data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING (Data Cleaning and Data Transformation on train and test csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some information:\n",
    "\n",
    "Distinguishing between a cat and a dog is an important problem of machine learning. \n",
    "We should know what a cat should look like and what a dog should look like\n",
    "\n",
    "Data set (Cat and Dog dataset)\n",
    "|\n",
    "Data Preprocessing (Rich features are features that are created fro existing features, this is called attribute selection with forward or backward propagation or decision tree)\n",
    "|\n",
    "Learning Model (Classification)\n",
    "|\n",
    "Performance Evaluation\n",
    "\n",
    "We can have a plot with circles and dogs with sqaures\n",
    "If a given data falls in the region of cats, it is a cat, and similarly for dog\n",
    "\n",
    "We can have lets say 15 attributes of 12 countries, the different countries will be in 15 dimensions, we cannot visualize this but machines can. This number of attributes might even be too less for a machine.\n",
    "\n",
    "Before data prepocessing, data cleaning will eliminate and thus reduce some attributes for the learning model.\n",
    "\n",
    "Remove the destination country, then use this information fed into the learning model to predict the destination country of a user.\n",
    "\n",
    "This is multiclass classification\n",
    "The dog and cat problem is a dual class classification.\n",
    "\n",
    "This notebook is compressed and we need to perform the analysis of the data ourselves.\n",
    "\n",
    "### Milestones:\n",
    "#### 1) Understanding the data\n",
    "Or rather understanding the literature of the data.\n",
    "Raise questions such as:\n",
    "What are the features, number of records, format of the data, how different features relate to each other\n",
    "\n",
    "##### Review the dataset\n",
    "We need more data beyond the given samples.\n",
    "\n",
    "A user might visit a site 10 times, before making a booking the 11th time. How to record sessions of a user. This is what is there in sessions.csv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Reading data...\n",
      "Reading data...completed\n",
      "Fixing timestamps...\n",
      "Fixing timestamps...completed\n",
      "Droped date_first_booking column...\n",
      "Fixing age column...\n",
      "Fixing age column...completed\n",
      "Filling first_affiliate_tracked column...\n",
      "Filling first_affiliate_tracked column...completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>gxn3p5htnn</td>\n",
       "      <td>820tgsjxq7</td>\n",
       "      <td>4ft3gnwmtx</td>\n",
       "      <td>bjjt8pjhuk</td>\n",
       "      <td>87mebub9p4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_account_created</th>\n",
       "      <td>2010-06-28 00:00:00</td>\n",
       "      <td>2011-05-25 00:00:00</td>\n",
       "      <td>2010-09-28 00:00:00</td>\n",
       "      <td>2011-12-05 00:00:00</td>\n",
       "      <td>2010-09-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <td>2009-03-19 04:32:55</td>\n",
       "      <td>2009-05-23 17:48:09</td>\n",
       "      <td>2009-06-09 23:12:47</td>\n",
       "      <td>2009-10-31 06:01:29</td>\n",
       "      <td>2009-12-08 06:11:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>-unknown-</td>\n",
       "      <td>MALE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>-unknown-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signup_method</th>\n",
       "      <td>facebook</td>\n",
       "      <td>facebook</td>\n",
       "      <td>basic</td>\n",
       "      <td>facebook</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signup_flow</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affiliate_channel</th>\n",
       "      <td>direct</td>\n",
       "      <td>seo</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affiliate_provider</th>\n",
       "      <td>direct</td>\n",
       "      <td>google</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_affiliate_tracked</th>\n",
       "      <td>untracked</td>\n",
       "      <td>untracked</td>\n",
       "      <td>untracked</td>\n",
       "      <td>untracked</td>\n",
       "      <td>untracked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signup_app</th>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_device_type</th>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Mac Desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_browser</th>\n",
       "      <td>Chrome</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>IE</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_destination</th>\n",
       "      <td>NDF</td>\n",
       "      <td>NDF</td>\n",
       "      <td>US</td>\n",
       "      <td>other</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0                    1  \\\n",
       "id                                gxn3p5htnn           820tgsjxq7   \n",
       "date_account_created     2010-06-28 00:00:00  2011-05-25 00:00:00   \n",
       "timestamp_first_active   2009-03-19 04:32:55  2009-05-23 17:48:09   \n",
       "gender                             -unknown-                 MALE   \n",
       "age                                     -1.0                 38.0   \n",
       "signup_method                       facebook             facebook   \n",
       "signup_flow                                0                    0   \n",
       "language                                  en                   en   \n",
       "affiliate_channel                     direct                  seo   \n",
       "affiliate_provider                    direct               google   \n",
       "first_affiliate_tracked            untracked            untracked   \n",
       "signup_app                               Web                  Web   \n",
       "first_device_type                Mac Desktop          Mac Desktop   \n",
       "first_browser                         Chrome               Chrome   \n",
       "country_destination                      NDF                  NDF   \n",
       "\n",
       "                                           2                    3  \\\n",
       "id                                4ft3gnwmtx           bjjt8pjhuk   \n",
       "date_account_created     2010-09-28 00:00:00  2011-12-05 00:00:00   \n",
       "timestamp_first_active   2009-06-09 23:12:47  2009-10-31 06:01:29   \n",
       "gender                                FEMALE               FEMALE   \n",
       "age                                     56.0                 42.0   \n",
       "signup_method                          basic             facebook   \n",
       "signup_flow                                3                    0   \n",
       "language                                  en                   en   \n",
       "affiliate_channel                     direct               direct   \n",
       "affiliate_provider                    direct               direct   \n",
       "first_affiliate_tracked            untracked            untracked   \n",
       "signup_app                               Web                  Web   \n",
       "first_device_type            Windows Desktop          Mac Desktop   \n",
       "first_browser                             IE              Firefox   \n",
       "country_destination                       US                other   \n",
       "\n",
       "                                           4  \n",
       "id                                87mebub9p4  \n",
       "date_account_created     2010-09-14 00:00:00  \n",
       "timestamp_first_active   2009-12-08 06:11:05  \n",
       "gender                             -unknown-  \n",
       "age                                     41.0  \n",
       "signup_method                          basic  \n",
       "signup_flow                                0  \n",
       "language                                  en  \n",
       "affiliate_channel                     direct  \n",
       "affiliate_provider                    direct  \n",
       "first_affiliate_tracked            untracked  \n",
       "signup_app                               Web  \n",
       "first_device_type                Mac Desktop  \n",
       "first_browser                         Chrome  \n",
       "country_destination                       US  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Exploring Traveler data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline \n",
    "\n",
    "print(\"Reading data...\")\n",
    "train_file = \"./traveler_dataset/train_users_2.csv\"\n",
    "df_train = pd.read_csv(train_file, header = 0,index_col=None)\n",
    "\n",
    "test_file = \"./traveler_dataset/test_users.csv\"\n",
    "df_test = pd.read_csv(test_file, header = 0,index_col=None)\n",
    "\n",
    "# Combining into one dataset for cleaning\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True, sort=False)\n",
    "print(\"Reading data...completed\")\n",
    "\n",
    "# Fixing date formats in Pandas - to_datetime\n",
    "## Change dates to specific format\n",
    "print(\"Fixing timestamps...\")\n",
    "df_all['date_account_created'] = pd.to_datetime(df_all['date_account_created'], format='%Y-%m-%d')\n",
    "df_all['timestamp_first_active'] = pd.to_datetime(df_all['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "print(\"Fixing timestamps...completed\")\n",
    "\n",
    "## Removing date_first_booking column\n",
    "df_all.drop('date_first_booking', axis = 1, inplace = True)\n",
    "print(\"Droped date_first_booking column...\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## Remove outliers function - [1]\n",
    "def remove_outliers(df, column, min_val, max_val):\n",
    "    col_values = df[column].values\n",
    "    df[column] = np.where(np.logical_or(col_values<=min_val, col_values>=max_val), np.NaN, col_values)\n",
    "    return df\n",
    "\n",
    "## Fixing age column - [2]\n",
    "print(\"Fixing age column...\")\n",
    "df_all = remove_outliers(df = df_all, column = 'age', min_val = 15, max_val = 90)\n",
    "df_all['age'].fillna(-1, inplace = True)\n",
    "print(\"Fixing age column...completed\")\n",
    "\n",
    "# Other column missing value - Fill first_affiliate_tracked column\n",
    "print(\"Filling first_affiliate_tracked column...\")\n",
    "df_all['first_affiliate_tracked'].fillna(-1, inplace=True)\n",
    "print(\"Filling first_affiliate_tracked column...completed\")\n",
    "\n",
    "# df_all.head()\n",
    "df_all.head().transpose()\n",
    "# transpose() transposes the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### [2] Data Transformation and Feature Extraction\n",
    "\n",
    "Data transformation is the conversion of data from one form to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Encoding categorical data...\n",
      "One Hot Encoding categorical data...completed\n",
      "Adding new fields...\n",
      "Adding new fields...completed\n",
      "Droping fields...\n",
      "Droping fields...completed\n"
     ]
    }
   ],
   "source": [
    "# Own implementation of One Hot Encoding - Data Transformation\n",
    "def convert_to_binary(df, column_to_convert):\n",
    "    categories = list(df[column_to_convert].drop_duplicates())\n",
    "\n",
    "    for category in categories:\n",
    "        cat_name = str(category).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\"-\", \"\").lower()\n",
    "        col_name = column_to_convert[:5] + '_' + cat_name[:10]\n",
    "        df[col_name] = 0\n",
    "        df.loc[(df[column_to_convert] == category), col_name] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "# One Hot Encoding\n",
    "print(\"One Hot Encoding categorical data...\")\n",
    "columns_to_convert = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df_all = convert_to_binary(df=df_all, column_to_convert=column)\n",
    "    df_all.drop(column, axis=1, inplace=True)\n",
    "print(\"One Hot Encoding categorical data...completed\")\n",
    "\n",
    "# Add new date related fields - Creating New Features\n",
    "print(\"Adding new fields...\")\n",
    "df_all['day_account_created'] = df_all['date_account_created'].dt.weekday\n",
    "df_all['month_account_created'] = df_all['date_account_created'].dt.month\n",
    "df_all['quarter_account_created'] = df_all['date_account_created'].dt.quarter\n",
    "df_all['year_account_created'] = df_all['date_account_created'].dt.year\n",
    "df_all['hour_first_active'] = df_all['timestamp_first_active'].dt.hour\n",
    "df_all['day_first_active'] = df_all['timestamp_first_active'].dt.weekday\n",
    "df_all['month_first_active'] = df_all['timestamp_first_active'].dt.month\n",
    "df_all['quarter_first_active'] = df_all['timestamp_first_active'].dt.quarter\n",
    "df_all['year_first_active'] = df_all['timestamp_first_active'].dt.year\n",
    "df_all['created_less_active'] = (df_all['date_account_created'] - df_all['timestamp_first_active']).dt.days\n",
    "print(\"Adding new fields...completed\")\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "print(\"Droping fields...\")\n",
    "columns_to_drop = ['date_account_created', 'timestamp_first_active', 'date_first_booking', 'country_destination']\n",
    "for column in columns_to_drop:\n",
    "    if column in df_all.columns:\n",
    "        df_all.drop(column, axis=1, inplace=True)\n",
    "print(\"Droping fields...completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of data in NDF and US, this is due to human bias. A human will teach a machine dicrimination by feeding it biased data.\n",
    "Data augmentation: Increasing the number of samples synthetically.\n",
    "\n",
    "Distinction between crocodiles and dinosaurs. I can capture crocodiles from anywhere with even live data, but for dinosaurs we can only get a small amount of data.\n",
    "How do we balance this? As the data for crocodiles there might be 10 lakh data and for dinosaurs only 1000.\n",
    "We can take let's say only 50k of data\n",
    "Even better would be data augmentation.\n",
    "\n",
    "A computer trained to recognize a human from top to bottom will not recognize a human is shown upside down.\n",
    "So we can rotate the image: that would be syntheetic data sample.\n",
    "\n",
    "Ways of data augmentation:\n",
    "Rotating an image\n",
    "Decreasing the dimensions of an image\n",
    "Translation of data\n",
    "\n",
    "These ways of data augmentation is good for images but not text? \n",
    "For text, we have data sampling.\n",
    "\n",
    "##### Analysis for building learning model:\n",
    "There might be a ton of data from 2014, but the data from let's say 2012 might be more useful for data analysis. We might work with the whole data but the since the highest number of entries are of 2014, our results may be biased. Our model should be unbiased and generalised.\n",
    "\n",
    "We can plot to see the amount of data from different years.\n",
    "\n",
    "See the issues with different attributes such as age (sometimes age is not even reported), etc.\n",
    "\n",
    "Booking through iphones could mean that those people are travelling domestically as domestic flights might mostly by booked by phones and international flights with laptops/PCs.\n",
    "\n",
    "75%+ people are using iphones and Macs. So Iphone and Mac users have increased. Users with unknown devices have decreased.\n",
    "\n",
    "#### 2) Cleaning the data\n",
    "\n",
    "fix timestamp formats\n",
    "Fill in missing values\n",
    "fix erroneous values\n",
    "Skipping of attributes (this is risky as we will be losing a whole attribute so take this decision visely based on our data, mostly we wont skip any attribute or record, we might fix it instead)\n",
    "\n",
    "Standardizing the categories:\n",
    "People from the US might fill in USA,US,America, etc. in the country. We need to ensure that we transform all these forms of country (this is a categorical data) to a standard form a machine can understand.\n",
    "\n",
    "We usually perform data cleaning before data augmentation without worrying about the bias.\n",
    "\n",
    "There is no standard order of steps for data preprocessing, If something works explain and prove how it did.\n",
    "\n",
    "Getting new attributes from the existing ones, such as getting the time between creation of an account and the first booking.\n",
    "\n",
    "##### Correcting erronous values:\n",
    "outliers\n",
    "missing values\n",
    "\n",
    "we store some default value such as -1 instead of having to deal with garbage values in attributes. You can replace NaN with -1.\n",
    "\n",
    "see np.where function to see how a condition affects the attributes of a given record.\n",
    "\n",
    "Write a function to remove NaN value ('remove' as in change NaN to -1)\n",
    "\n",
    "We can have 4 classes or columns and count the instances of that class. If a given instance belongs to say, class A, we mark that has 1, otherwise 0.\n",
    "\n",
    "We will records correlating with the 4 classes:\n",
    "\n",
    "Rx: M F O\n",
    "R1: 1 0 0 \n",
    "R2: 0 1 0\n",
    "R3: 0 0 1\n",
    "R4: 1 0 0\n",
    "\n",
    "Here, we are using one-hot encoding. Google it.\n",
    "\n",
    "##### Data transformation and feature extraction as a concept\n",
    "\n",
    "A machine will get biased with big and small numbers.\n",
    "\n",
    "Why data transformation:\n",
    "\n",
    "methods of this:\n",
    "bucketing/binning\n",
    "normalization\n",
    "other transformations\n",
    "one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Preprocessing Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
